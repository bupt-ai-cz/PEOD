# PEOD: A Pixel-Aligned Event-RGB Benchmark for Object Detection under Challenging Conditions

<div align="center"

<div align="center">

[![Project Page](https://img.shields.io/badge/ğŸŒ_Project_Page-Visit_Our_Website-blue?style=for-the-badge)](https://EchosLiu.github.io/PEOD-dataset/)
[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-AAAI_2026-red?style=for-the-badge)](https://EchosLiu.github.io/PEOD-dataset/)
[![Dataset](https://img.shields.io/badge/ğŸ“Š_Dataset-Coming_Soon-green?style=for-the-badge)](https://EchosLiu.github.io/PEOD-dataset/)

[**ğŸš€ View Interactive Demo**](https://EchosLiu.github.io/PEOD-dataset/) | [**ğŸ“– Documentation**](https://EchosLiu.github.io/PEOD-dataset/) | [**ğŸ’¾ Download**](https://EchosLiu.github.io/PEOD-dataset/)

</div>

---

## ğŸ¯ Overview

**PEOD** is the first large-scale dataset providing synchronized high-resolution event streams and RGB images for object detection under challenging conditions. This groundbreaking dataset addresses the critical need for robust perception systems that can operate reliably across diverse environmental conditions, particularly in scenarios where traditional frame-based sensors struggle.

<div align="center">
<img src="assets/images/datasetshow.png" alt="PEOD Dataset Overview" width="800"/>
</div>

### ğŸ”¬ Key Contributions

- **ğŸ¥ High-Resolution Multimodal Data**: 1280Ã—720 pixel-aligned event streams and RGB frames captured using a coaxial dual-camera system
- **ğŸŒ Comprehensive Coverage**: 120+ driving sequences across urban, suburban, and tunnel environments
- **ğŸŒ™ Challenging Conditions**: 57% of data collected under low light, overexposed, or high-speed conditions
- **ğŸ·ï¸ Rich Annotations**: 340k manually verified bounding boxes across six object classes
- **âš¡ High Dynamic Range**: Event camera with >87 dB HDR for extreme illumination scenarios

## ğŸ“Š Dataset Statistics

| **Metric** | **Value** | **Description** |
|------------|-----------|-----------------|
| **Resolution** | 1280Ã—720 | High-resolution pixel-aligned streams |
| **Sequences** | 120+ | Diverse driving scenarios |
| **Total Frames** | 72k | Synchronized RGB and event data |
| **Annotations** | 340k | Manually verified bounding boxes |
| **Frequency** | 30 Hz | High-frequency data capture |
| **Classes** | 6 | car, bus, truck, two-wheeler, three-wheeler, person |
| **Dynamic Range** | >87 dB | Event camera HDR capability |

## ğŸ“ Dataset Structure

```
PEOD/
â”œâ”€â”€ rgb/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ sequence_001             # the first RGB sequence
â”‚   â”‚   â”‚   â”œâ”€â”€ sequence_001_0001.png          # the first RGB frame
â”‚   â”‚   â”‚   â”œâ”€â”€ sequence_001_0001.png          # the second RGB frame
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ sequence_002                       # the second RGB sequence
â”‚   â”‚   â””â”€â”€ ...                                
â”‚   â””â”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ challenge/                         # the Illumination Challenge Subset
â”‚   â”‚   â”‚   â”œâ”€â”€ sequence_001_test              # the first illumination challenge sequence
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ nromal/                            # the Normal Subset
â”‚   â”‚   â”‚   â”œâ”€â”€ sequence_013_test              # the first normal sequence
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”œâ”€â”€ event/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ sequence_001.dat              
â”‚   â”‚   â”œâ”€â”€ sequence_002.dat
â”‚   â”‚   â””â”€â”€ ...              
â”‚   â””â”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ challenge/                         
â”‚   â”‚   â”‚   â”œâ”€â”€ sequence_001_test.dat          
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ nromal/                            
â”‚   â”‚   â”‚   â”œâ”€â”€ sequence_013_test.dat            
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”œâ”€â”€ timestamp/
â”‚   â””â”€â”€ [similar structure]
â””â”€â”€ annotations/
    â””â”€â”€ [similar structure]
```

## ğŸ¯ Object Classes

The dataset includes six carefully selected object classes relevant to autonomous driving:

| **Class** | **Description** | **Typical Scenarios** |
|-----------|-----------------|----------------------|
| **Car** | Standard passenger vehicles | Urban/suburban driving |
| **Person** | Pedestrians | Crosswalks, sidewalks |
| **Bus** | Public transportation vehicles | City centers, bus routes |
| **Truck** | Commercial vehicles | Highways, industrial areas |
| **Two-wheeler** | Motorcycles, bicycles | Urban intersections |
| **Three-wheeler** | Auto-rickshaws, tricycles | Developing urban areas |


## ğŸŒŸ Unique Features

### ğŸ”„ Perfect Pixel Alignment
Our coaxial dual-camera system ensures precise spatial correspondence between event and RGB data, enabling accurate multimodal fusion.

### ğŸŒ“ Challenging Conditions
- **Low light scenarios**: Twilight, dawn, underground passages
- **High-speed motion**: Highway driving, rapid camera movements  
- **Extreme illumination**: Direct sunlight, headlight glare, tunnel exits

### âš¡ Event Camera Advantages
- **High temporal resolution**: Microsecond precision
- **High dynamic range**: >87 dB vs ~60 dB for standard cameras
- **Motion blur immunity**: Sharp perception during rapid movement
- **Low latency**: Real-time perception capabilities

## ğŸ“¥ Download & Access

> ğŸš§ **Dataset Release**: The PEOD dataset will be publicly available soon. Please check our [Baidu Netdisk](https://EchosLiu.github.io/PEOD-dataset/) for the latest updates.

**Planned Formats:**
- **RAW format**: Unprocessed event and RGB data
- **DAT format**: Preprocessed event representations
- **Annotations**: NumPy arrays with bounding box coordinates

## ğŸ“š Citation

If you use PEOD in your research, please cite our paper(forthcoming):

```bibtex
@article{cui2025peod,
  title={PEOD: A Pixel-Aligned Event-RGB Benchmark for Object Detection under Challenging Conditions},
  author={Cui, Luoping and Liu, Hanqing and Liu, Mingjie and Lin, Endian and Jiang, Donghong and Wang, Yuhao and Zhu, Chuang},
  journal={arXiv preprint arXiv:2511.08140},
  year={2025}
}
```

## ğŸ¤ Contributing

We welcome contributions to improve the dataset and benchmark! Please see our [project page](https://EchosLiu.github.io/PEOD-dataset/) for contribution guidelines.

## ğŸ“„ License

This dataset is released under MIT License. Please refer to our [License](https://github.com/bupt-ai-cz/PEOD/blob/main/Term%20of%20Use%20and%20License.md) for detailed licensing information.

## ğŸ“ Contact

For questions, suggestions, or collaboration opportunities:

- **Project Page**: [https://EchosLiu.github.io/PEOD-dataset/](https://EchosLiu.github.io/PEOD-dataset/)
- **Issues**: Please use GitHub Issues for technical questions
- **Email**: 3254827845@qq.comï¼›3371665749@qq.comï¼›786896078@qq.com

---

<div align="center">

**ğŸŒŸ Star this repository if you find PEOD useful for your research! ğŸŒŸ**

[![GitHub stars](https://img.shields.io/github/stars/PEOD-dataset/PEOD-dataset?style=social)](https://github.com/PEOD-dataset/PEOD-dataset/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/PEOD-dataset/PEOD-dataset?style=social)](https://github.com/PEOD-dataset/PEOD-dataset/network/members)

</div>
